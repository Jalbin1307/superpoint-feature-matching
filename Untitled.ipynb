{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac525b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*-coding:utf8-*-\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# from utils.tensor_op import pixel_shuffle\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "def pixel_shuffle(tensor, scale_factor):\n",
    "    \"\"\"\n",
    "    Implementation of pixel shuffle using numpy\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    tensor: input tensor, shape is [N, C, H, W]\n",
    "    scale_factor: scale factor to up-sample tensor\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tensor: tensor after pixel shuffle, shape is [N, C/(r*r), r*H, r*W],\n",
    "        where r refers to scale factor\n",
    "    \"\"\"\n",
    "    num, ch, height, width = tensor.shape\n",
    "    assert ch % (scale_factor * scale_factor) == 0\n",
    "\n",
    "    new_ch = ch // (scale_factor * scale_factor)\n",
    "    new_height = height * scale_factor\n",
    "    new_width = width * scale_factor\n",
    "\n",
    "    tensor = tensor.reshape(\n",
    "        [num, new_ch, scale_factor, scale_factor, height, width])\n",
    "    # new axis: [num, new_ch, height, scale_factor, width, scale_factor]\n",
    "    tensor = tensor.permute(0, 1, 4, 2, 5, 3)\n",
    "    tensor = tensor.reshape(num, new_ch, new_height, new_width)\n",
    "    return tensor\n",
    "\n",
    "class SuperPointNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The magicleap definition of SuperPoint Network.\n",
    "    Mainly for debug or export homography adaptations\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channel=1, grid_size=8):\n",
    "        super(SuperPointNet, self).__init__()\n",
    "\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
    "        # Shared Encoder.\n",
    "        self.conv1a = torch.nn.Conv2d(input_channel, c1, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1b = torch.nn.Conv2d(c1, c1, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2a = torch.nn.Conv2d(c1, c2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2b = torch.nn.Conv2d(c2, c2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3a = torch.nn.Conv2d(c2, c3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3b = torch.nn.Conv2d(c3, c3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4a = torch.nn.Conv2d(c3, c4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4b = torch.nn.Conv2d(c4, c4, kernel_size=3, stride=1, padding=1)\n",
    "        # Detector Head.\n",
    "        self.convPa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "        self.convPb = torch.nn.Conv2d(c5, 65, kernel_size=1, stride=1, padding=0)\n",
    "        # Descriptor Head.\n",
    "        self.convDa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "        self.convDb = torch.nn.Conv2d(c5, d1, kernel_size=1, stride=1, padding=0)\n",
    "        #\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
    "        tensors.\n",
    "        Input\n",
    "          x: Image pytorch tensor shaped N x 1 x H x W.\n",
    "        Output\n",
    "          semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
    "          desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
    "        \"\"\"\n",
    "        if isinstance(x, dict):\n",
    "            x = x['img']\n",
    "\n",
    "        # Shared Encoder.\n",
    "        x = self.relu(self.conv1a(x))\n",
    "        x = self.relu(self.conv1b(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2a(x))\n",
    "        x = self.relu(self.conv2b(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        \n",
    "        # Detector Head.\n",
    "        cPa = self.relu(self.convPa(x))\n",
    "        semi = self.convPb(cPa)\n",
    "        #\n",
    "        prob = self.softmax(semi)\n",
    "        prob = prob[:, :-1, :, :]  # remove dustbin,[B,64,H,W]\n",
    "        # Reshape to get full resolution heatmap.\n",
    "        prob = pixel_shuffle(prob, self.grid_size)  # [B,1,H*8,W*8]\n",
    "        prob = prob.squeeze(dim=1)#[B,H,W]\n",
    "\n",
    "        # Descriptor Head, useless for export image key points\n",
    "        cDa = self.relu(self.convDa(x))\n",
    "        out = self.convDb(cDa)\n",
    "        dn = torch.norm(out, p=2, dim=1)  # Compute the norm.\n",
    "        desc_raw = out.div(torch.unsqueeze(dn, 1))  # Divide by norm to normalize.\n",
    "        ##\n",
    "        # # interpolation\n",
    "        desc = F.interpolate(desc_raw, scale_factor=self.grid_size, mode='bilinear', align_corners=False)\n",
    "        desc = F.normalize(desc, p=2, dim=1)  # normalize by channel\n",
    "\n",
    "        prob = {'logits':semi, 'prob':prob}\n",
    "        desc = {'desc_raw':desc_raw, 'desc':desc}\n",
    "        return prob, desc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d09ded3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "model = SuperPointNet()\n",
    "model.load_state_dict(torch.load('./superpoint_v1.pth'))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fe56642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 320)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img_path = './data/images/COCO_train2014_000000000009.jpg'\n",
    "\n",
    "img = cv2.imread(img_path, 0)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac288f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(img, dtype=torch.float32)\n",
    "x = x.unsqueeze(0)\n",
    "x = x.unsqueeze(0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bec203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2696f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 65, 30, 40]) torch.Size([1, 240, 320])\n",
      "torch.Size([1, 256, 30, 40]) torch.Size([1, 256, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "print(out[0]['logits'].shape, out[0]['prob'].shape)\n",
    "print(out[1]['desc_raw'].shape, out[1]['desc'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "216e3c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 240, 320, 256]) torch.Size([1, 240, 320])\n"
     ]
    }
   ],
   "source": [
    "desc = out[1]['desc']\n",
    "prob = out[0]['prob']\n",
    "\n",
    "num, dv, height, width = desc.shape\n",
    "\n",
    "desc = desc.reshape(num, height, width, dv)\n",
    "\n",
    "print(desc.shape, prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ca9879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240, 320, 256])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39a056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
